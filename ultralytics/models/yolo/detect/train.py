# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import math
import random
from copy import copy

import numpy as np
import torch.nn as nn

from ultralytics.data import build_dataloader, build_yolo_dataset, build_mutil_dataloader
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models import yolo
from ultralytics.nn.tasks import DetectionModel
from ultralytics.utils import LOGGER, RANK
from ultralytics.utils.plotting import plot_images, plot_labels, plot_results
from ultralytics.utils.torch_utils import de_parallel, torch_distributed_zero_first


class DetectionTrainer(BaseTrainer):
    """
    ä¸€ä¸ªæ‰©å±•BaseTrainerç±»çš„ç±»ï¼Œç”¨äºåŸºäºæ£€æµ‹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚

    Example:
        ```python
        from ultralytics.models.yolo.detect import DetectionTrainer

        # ç”Ÿæˆå­—å…¸å†ä¼ ä¼ å…¥
        args = dict(model="yolo11n.pt", data="coco8.yaml", epochs=3)
        trainer = DetectionTrainer(overrides=args)
        trainer.train()
        ```
    """

    def build_dataset(self, img_path, mode="train", batch=None):
        """
        ç”Ÿæˆyolo DataSets.

        Args:
            img_path (str): åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
            mode (str): `train` mode or `val` mode, ç”¨æˆ·å¯ä»¥ä¸ºæ¯ç§æ¨¡å¼å®šåˆ¶ä¸åŒçš„å¢å¼ºåŠŸèƒ½ã€‚
            batch (int, optional): æ‰¹é‡å¤§å°ï¼Œè¿™æ˜¯é’ˆå¯¹â€œrectâ€çš„ã€‚é»˜è®¤ä¸ºâ€œNoneâ€ã€‚
        """
        # de_parallel(self.model).stride.max()å–å‡ºæ¨¡å‹ä¸­æœ€å¤§çš„æ­¥é•¿ ç„¶ågs=stride maxå’Œ32ä¸­çš„max
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)

        # self.dataæ˜¯è§£æåçš„æ•°æ®é›†å…¨éƒ¨çš„ä¿¡æ¯å’Œè·¯å¾„ã€‚ img_pathæ˜¯è®­ç»ƒ/æµ‹è¯•çš„æ•°æ®é›† è¿”å›ä¸€ä¸ªpytroché‡æ„çš„datasetå¯¹è±¡
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """æ„å»ºå¹¶ä¸”è¿”å›ä¸€ä¸ª dataloader."""
        assert mode in {"train", "val"}, f"Mode must be 'train' or 'val', not {mode}."
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
            dataset = self.build_dataset(dataset_path, mode, batch_size)
        shuffle = mode == "train"
        if getattr(dataset, "rect", False) and shuffle:
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")
            shuffle = False
        workers = self.args.workers if mode == "train" else self.args.workers * 2

        # è¿”å›ä¸€ä¸ªpytroché‡æ„çš„dataloaderå¯¹è±¡
        return build_dataloader(dataset, batch_size, workers, shuffle, rank)

    def get_mutil_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """æ„å»ºå¹¶ä¸”è¿”å›ä¸¤ä¸ª dataloader."""
        assert mode in {"train", "val"}, f"Mode must be 'train' or 'val', not {mode}."
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
            if isinstance(dataset_path, list):
                dataset1 = self.build_dataset(dataset_path[0], mode, batch_size) # 0æ˜¯ä¸Šé¢çš„ä¸ºvis
                dataset2 = self.build_dataset(dataset_path[1], mode, batch_size)
        shuffle = mode == "train"
        if getattr(dataset1, "rect", False) and shuffle:
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")
            shuffle = False
        if getattr(dataset2, "rect", False) and shuffle:
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")
            shuffle = False
        workers = self.args.workers if mode == "train" else self.args.workers * 2

        # è¿”å›ä¸€ä¸ªpytroché‡æ„çš„dataloaderå¯¹è±¡
        return build_mutil_dataloader(dataset1, dataset2, batch_size, workers, shuffle, rank)

    def preprocess_batch(self, batch):
        """é€šè¿‡ç¼©æ”¾å’Œè½¬æ¢ä¸ºæµ®ç‚¹æ•°æ¥é¢„å¤„ç†ä¸€æ‰¹å›¾åƒã€‚"""
        batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 255
        if self.args.multi_scale:
            imgs = batch["img"]
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # size
            sf = sz / max(imgs.shape[2:])  # scale factor
            if sf != 1:
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # new shape (stretched to gs-multiple)
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)
            batch["img"] = imgs
        return batch

    def preprocess_multi_batch(self, batch):
        """
        å¯¹ä¸¤ä¸ªæ•°æ®æºï¼ˆir å’Œ rgbï¼‰åŒæ—¶è¿›è¡Œç»Ÿä¸€çš„é¢„å¤„ç†ï¼Œç¡®ä¿å°ºå¯¸ä¸€è‡´ã€‚

        Args:
            batch (dict): åŒ…å« 'ir' å’Œ 'rgb' æ•°æ®çš„å­—å…¸ã€‚

        Returns:
            dict: é¢„å¤„ç†åçš„ batchï¼Œ'ir' å’Œ 'rgb' æ•°æ®å…·æœ‰ä¸€è‡´çš„å°ºå¯¸ã€‚
        """
        # å¤„ç† rgb å›¾åƒ
        batch["rgb"]["img"] = batch["rgb"]["img"].to(self.device, non_blocking=True).float() / 255
        # å¤„ç† ir å›¾åƒ
        batch["ir"]["img"] = batch["ir"]["img"].to(self.device, non_blocking=True).float() / 255

        if self.args.multi_scale:
            # è·å– ir å’Œ rgb çš„æœ€å¤§å°ºå¯¸
            imgs_rgb = batch["rgb"]["img"]
            imgs_ir = batch["ir"]["img"]
            max_dim = max(
                max(batch["rgb"]["img"].shape[2:]),  # rgb æœ€å¤§å°ºå¯¸
                max(batch["ir"]["img"].shape[2:])  # ir æœ€å¤§å°ºå¯¸
            )
            # è®¡ç®—ç›®æ ‡å°ºå¯¸ï¼ˆç»Ÿä¸€ä¸º stride çš„å€æ•°ï¼‰
            sz = (
                    random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                    // self.stride
                    * self.stride
            )  # size
            # è®¡ç®—ç¼©æ”¾å› å­
            sf = sz / max_dim  # scale factor
            if sf!=1:
                # è®¡ç®—æ–°çš„å°ºå¯¸
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs_ir.shape[2:]
                ]  # new shape (stretched to gs-multiple)

                # å¯¹ ir å’Œ rgb åŒæ­¥æ’å€¼ç¼©æ”¾
                imgs_rgb = nn.functional.interpolate(imgs_rgb, size=ns, mode="bilinear", align_corners=False)
                imgs_ir = nn.functional.interpolate(imgs_ir, size=ns, mode="bilinear", align_corners=False)
            batch["rgb"]["img"] = imgs_rgb
            batch["ir"]["img"] = imgs_ir
        return batch["rgb"], batch["ir"]

    def set_model_attributes(self):
        """Nl = de_parallel(self.model).model[-1].nl  # number of detection layers (to scale hyps)."""
        # self.args.box *= 3 / nl  # scale to layers
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  #scale to classes and layers
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # scale to image size and layers
        self.model.nc = self.data["nc"]  # attach number of classes to model
        self.model.names = self.data["names"]  # attach class names to model
        self.model.args = self.args  # attach hyperparameters to model
        # æœ€åä¸€è¡Œçš„æ³¨é‡Šå¯èƒ½æ˜¯ä¸€ä¸ªå¾…åŠäº‹é¡¹ï¼Œè¡¨ç¤ºä½œè€…è®¡åˆ’åœ¨æœªæ¥æ·»åŠ ä¸€ä¸ªæ ¹æ®æ•°æ®é›†æ ‡ç­¾è®¡ç®—ç±»åˆ«æƒé‡å¹¶å°†å…¶é™„åŠ åˆ°æ¨¡å‹ä¸Šçš„åŠŸèƒ½ã€‚
        # è¿™å¯èƒ½æ˜¯ä¸ºäº†å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå³æ•°æ®é›†ä¸­æŸäº›ç±»åˆ«çš„æ ·æœ¬æ•°é‡æ¯”å…¶ä»–ç±»åˆ«å¤šå¾—å¤šã€‚
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    # ä»è¿™é‡Œè¿›å…¥çš„DetectionModel
    def get_model(self, cfg=None, weights=None, verbose=True):
        """è¿”å› a YOLO detection model."""
        # ä»è¿™é‡Œè¿›å…¥çš„DetectionModel
        model = DetectionModel(cfg, nc=self.data["nc"], verbose=verbose and RANK == -1)

        # å¦‚æœæœ‰é¢„è®­ç»ƒæƒé‡è¿›è¡ŒåŠ è½½
        if weights:
            model.load(weights)
        return model

    def get_validator(self):
        """è¿”å› a DetectionValidator for YOLO model validation."""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss" # ä¸‰ä¸ªæŸå¤±çš„åç§°
        return yolo.detect.DetectionValidator(
            self.test_loader, save_dir=self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )

    def get_mutil_validator(self):
        """è¿”å› a DetectionValidator for YOLO model validation."""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss" # ä¸‰ä¸ªæŸå¤±çš„åç§°
        return yolo.detect.DetectionValidator(
            [self.test_loader, self.test_ir_loader], save_dir=self.save_dir,
            args=copy(self.args), _callbacks=self.callbacks, infusion = True
        )

    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        è¿”å›ä¸€ä¸ªå¸¦æœ‰æ ‡è®°çš„è®­ç»ƒæŸå¤±é¡¹å¼ é‡çš„æŸå¤±å­—å…¸ã€‚

        Not needed for classification but necessary for segmentation & detection
        """
        keys = [f"{prefix}/{x}" for x in self.loss_names]
        if loss_items is not None:
            loss_items = [round(float(x), 5) for x in loss_items]  # convert tensors to 5 decimal place floats
            return dict(zip(keys, loss_items))
        else:
            return keys

    # è¿”å›æ¯ä¸ªepochçš„åŠ è½½ä¿¡æ¯
    def progress_string(self):
        """Returns a formatted string of training progress with epoch, GPU memory, loss, instances and size."""
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (
            "Epoch",
            "GPU_mem",
            *self.loss_names,
            "Instances",
            "Size",
        )

    # ä¸‹é¢ä¸‰ä¸ªéƒ½æ˜¯ç”»å›¾
    def plot_training_samples(self, batch, ni):
        """Plots training samples with their annotations."""
        plot_images(
            images=batch["img"],
            batch_idx=batch["batch_idx"],
            cls=batch["cls"].squeeze(-1),
            bboxes=batch["bboxes"],
            paths=batch["im_file"],
            fname=self.save_dir / f"train_batch{ni}.jpg", #æ–‡ä»¶å
            on_plot=self.on_plot,
        )

    def plot_metrics(self):
        """Plots metrics from a CSV file."""
        plot_results(file=self.csv, on_plot=self.on_plot)  # save results.png

    def plot_training_labels(self):
        """Create a labeled training plot of the YOLO model."""
        boxes = np.concatenate([lb["bboxes"] for lb in self.train_loader.dataset.labels], 0)
        cls = np.concatenate([lb["cls"] for lb in self.train_loader.dataset.labels], 0)
        plot_labels(boxes, cls.squeeze(), names=self.data["names"], save_dir=self.save_dir, on_plot=self.on_plot)
